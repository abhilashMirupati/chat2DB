Metadata-Version: 2.4
Name: sqlai
Version: 0.1.0
Summary: Cross-database natural language analytics agent with visualization.
Author: SQLAI
License: MIT
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: langchain>=0.2.0
Requires-Dist: langchain-community>=0.2.0
Requires-Dist: langgraph>=0.0.50
Requires-Dist: sqlalchemy>=2.0.0
Requires-Dist: oracledb>=2.0.0
Requires-Dist: pandas>=2.1.0
Requires-Dist: plotly>=5.20.0
Requires-Dist: streamlit>=1.35.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pydantic>=2.4.0
Requires-Dist: pydantic-settings>=2.0.0
Requires-Dist: tabulate>=0.9.0
Requires-Dist: tenacity>=8.2.0
Requires-Dist: huggingface-hub>=0.23.0
Requires-Dist: sqlparse>=0.4.4
Requires-Dist: numpy>=1.24.0
Requires-Dist: requests>=2.31.0
Provides-Extra: openai
Requires-Dist: openai>=1.3.0; extra == "openai"
Requires-Dist: langchain-openai>=0.1.0; extra == "openai"
Provides-Extra: anthropic
Requires-Dist: anthropic>=0.25.0; extra == "anthropic"
Requires-Dist: langchain-anthropic>=0.1.0; extra == "anthropic"
Provides-Extra: ollama
Requires-Dist: ollama>=0.3.0; extra == "ollama"
Requires-Dist: langchain-ollama>=0.1.0; extra == "ollama"
Provides-Extra: huggingface
Requires-Dist: huggingface_hub>=0.19.0; extra == "huggingface"
Requires-Dist: langchain-huggingface>=0.1.0; extra == "huggingface"
Provides-Extra: snowflake
Requires-Dist: snowflake-sqlalchemy>=1.5.0; extra == "snowflake"
Provides-Extra: mysql
Requires-Dist: pymysql>=1.1.0; extra == "mysql"
Provides-Extra: postgres
Requires-Dist: psycopg2-binary>=2.9.9; extra == "postgres"
Provides-Extra: mssql
Requires-Dist: pyodbc>=5.1.0; extra == "mssql"

 # SQLAI
 
 Natural language analytics agent that can explore any SQL database (Oracle, Postgres, MySQL, SQL Server, etc.), summarise findings, and produce visualisations.
 
## Highlights

- **Plug-and-play database support** using SQLAlchemy; connect to Oracle or any other relational engine.
- **Graph-RAG prompt context** – we build table / column / foreign-key cards, sample values, and a dialect guide so SQL is grounded in real metadata.
- **Semantic retrieval (optional)** – Hugging Face or Ollama embeddings help the agent understand fuzzy, business-friendly wording at scale.
- **Guard → Repair → Summarise** – generated SQL is linted, repaired (schema prefixes, row caps) and surfaced with notes before we ever hit the database.
- **Streamlit UI** for configuration, question history, and interactive data/plot rendering.
- **Pandas + Plotly** for tabular exploration, including guardrails on chart specs.
 
 ## Project Structure
 
 ```
 SQLAI/
 ├─ run_app.py                  # Launches Streamlit UI
 ├─ pyproject.toml              # Python dependencies & configuration
 ├─ README.md                   # You are here
 └─ src/sqlai
    ├─ __init__.py
    ├─ config.py                # Pydantic configs for DB/LLM/app
    ├─ agents/                  # LangGraph workflows
    ├─ database/                # SQLAlchemy engine + schema introspection
    ├─ llm/                     # Provider plumbing & prompts
    ├─ services/                # High-level analytics & visualisation services
    ├─ ui/                      # Streamlit app
    └─ utils/                   # Logging helpers, etc.
 ```
 
 ## Getting Started
 
 1. **Install dependencies**
 
    ```bash
    python -m venv .venv
    .venv\Scripts\activate      # Windows
    # source .venv/bin/activate # macOS/Linux
    pip install -e ".[openai,anthropic,ollama,huggingface]"
    ```
 
    > Install only the extras that match the LLMs you plan to use.
 
 2. **Configure environment**
 
    Create a `.env` file in the project root:
 
    ```env
    SQLAI_DB_URL=oracle+oracledb://user:password@hostname:1521/?service_name=ORCLPDB1
    SQLAI_DB_SCHEMA=QA_RESULTS
    SQLAI_LLM_PROVIDER=ollama
    SQLAI_LLM_MODEL=llama3
    SQLAI_LLM_BASE_URL=http://localhost:11434
    # SQLAI_LLM_API_KEY=...    # Needed for hosted LLMs
   SQLAI_EMBED_PROVIDER=none  # Set to huggingface or ollama for semantic retrieval
   # SQLAI_EMBED_MODEL=google/embeddinggemma-300m
   # SQLAI_EMBED_API_KEY=...   # Required when provider=huggingface
    ```
 
    Optional knobs:
 
    - `SQLAI_DB_SAMPLE_ROW_LIMIT`: change schema sampling rows
    - `SQLAI_LLM_TEMPERATURE`, `SQLAI_LLM_MAX_OUTPUT_TOKENS`
   - `SQLAI_EMBED_MODEL`, `SQLAI_EMBED_BASE_URL`
 
    For Oracle, ensure the [python-oracledb driver](https://python-oracledb.readthedocs.io/) prerequisites are satisfied. For other databases, adjust the URL accordingly (SQLAlchemy format).
 
 3. **Run the UI**
 
    ```bash
    python run_app.py
    ```
 
    Open the Streamlit URL shown in the terminal (default `http://localhost:8501`).
 
 ## Using the Agent
 
1. Open the sidebar to configure database + LLM (or rely on `.env` defaults).
2. (Optional) choose an **Embedding provider** (Hugging Face hosted or Ollama self-hosted) if you need semantic retrieval across hundreds of tables.
3. Click **Initialise Agent** to connect, introspect the schema, and build the graph cache.
4. Ask questions like:
   - “Which test set has the highest failure rate this month?”
   - “List the top 10 failure reasons for suite `MOBILE_REGRESSION`.”
   - “How many executions passed today, and what’s the top failure reason?”
5. Review generated SQL, guard/repair notes, table previews, summaries, and charts inline. Conversation history appears in the main panel for quick drill-downs.
 
 ## Architecture Walkthrough
 
 - `database.connectors` – builds SQLAlchemy engines, tests connectivity.
- `database.schema_introspector` – reads table/column/foreign-key metadata, comments, and row estimates.
- `graph.context` – turns that metadata into table / column / relationship “cards”.
- `semantic.retriever` – blends heuristics with optional Hugging Face / Ollama similarity scoring.
- `agents.guard` – validates SQL, adds missing schema prefixes, enforces row caps, and reports execution errors.
- `services.domain_fallbacks` – domain-aware fallbacks (e.g. failure-reason rollups) when the model hesitates.
- `llm.providers` – load LangChain-compatible chat models across providers.
- `agents.query_agent` – LangGraph nodes: **plan** (LLM + Graph-RAG charter), **execute** (guard + Pandas), **summarise** (LLM explanation).
- `services.analytics_service` – orchestrates engine, graph context, guard/fallback workflow execution.
- `services.visualization` – converts LLM chart specs into Plotly figures.
- `ui.app` – Streamlit front-end with configuration controls and results rendering.
 
 The design keeps provider/database specifics isolated, making it easy to swap in new tools (e.g. Snowflake, Databricks, or a custom LLM).
 
## Guardrails at a Glance

- **Graph-RAG charter** instructs the model to use only in-context tables/columns and to produce strict JSON with evidence/tests/summary.
- **SQL guard/repair** ensures referenced tables exist, prefixes schema names when they are omitted, and automatically applies row limits.
- **Fallbacks**: metadata questions (`COUNT tables`, `list tables`) and a failure-reason rollup template return deterministic SQL when the LLM defers.
- **Execution tracing**: plan notes, guard warnings, and row samples are logged to the console (`SQLAI_LOG_LEVEL=DEBUG`) and surfaced in the UI.

 ## Extending the System
 
- **Semantic search at scale**: wire up Chroma/pgvector for persisted embeddings if you need 1000+ table recall.
- **Domain templates**: add more fallbacks in `services/domain_fallbacks.py` for your most common analytics asks.
- **Conversation memory**: persist conversation state (e.g. selected IDs) to support drill-down follow-up questions.
- **Advanced visualisations**: expand `visualization.py` to support time-series decomposition, dashboards, etc.
- **Caching**: persist the graph context (tables, embeddings, samples) in `cache_dir` and refresh only when schema diffs are detected.
- **Auth & multi-tenancy**: wrap `AnalyticsService` in a FastAPI backend and authenticate Streamlit requests.
 
 ## Testing
 
 Add unit tests under `tests/`. Suggested areas:
 
 - Mock database engines to validate schema parsing.
- Prove that plan JSON is validated/guarded before execution.
- Validate chart builder behaviour and guard warnings for various specs.
 
 ## Troubleshooting
 
 - **Oracle connectivity**: verify that `oracledb` can connect via `python -c "import oracledb; ..."` and that Oracle Instant Client is installed if using thick mode.
 - **LLM provider errors**: ensure the relevant `langchain-*` package and API keys are installed/configured.
- **Embedding provider errors**: confirm `SQLAI_EMBED_MODEL` and `SQLAI_EMBED_API_KEY` (for Hugging Face) are set; the Streamlit sidebar surfaces validation errors.
 - **Unexpected SQL**: tighten prompts or add custom validation before executing queries.
 
 ---
 
 Built to scale from a sample schema to enterprise-grade test automation data lakes.

